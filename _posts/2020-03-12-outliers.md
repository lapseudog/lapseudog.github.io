---
layout: post
author: lapseudog
---

# How are performing common outliers detection techniques with real data?
Common outliers detection techniques are usually illustrated with the help of the Normal distribution, however the data used by these techniques is not always distributed that way. While the behaviour of the Normal distribution is usually well known, the other distributions are less known. Hence mistakes could be made, but can we measure it? Several outliers detection techniques are presented here and tested against univariate data; several distributions are selected and compared. 
A few outliers detection techniques have been selected, because they are commonly referred to on online articles or mentioned in vendor documentations. Generally these techniques involve selecting a central point of the data, and measuring the distance from the central point by a dispersion measure. As the purpose is to provide a measure, techniques based on visual inspection are not used.
## Outliers detection techniques
The techniques are:
* Mean and Standard Deviation (SD), also known as the z-score. The central point of the data is the arithmetic mean, and the measure of dispersion is the standard deviation. 
* Median and Median Absolute Deviation (MAD). The central point of the data is the median (or 50th percentile), and the measure of dispersion is the Median Absolute Deviation.
* Median and interquartile range, also known as interquartile deviation (IQD) method. The central point is the median, and the interquartile range is the measure of dispersion.
## Measuring the impact
For data taken from a normal distribution the relation between the number of standard deviations and the percentile rank is known. So for the purpose of comparison letâ€™s use the percentile rank associated with the Normal distribution as the standard. Some distributions are symmetrical (such as the Normal Distribution) and other not. No difference was made as the objective was to measure the raw results.

## Results with common distributions

|Distribution | Rank of mean +2 SD| Rank of mean +3 SD|Rank of MAD +2| Rank of MAD +3|Rank of IQD +2| Rank of IQD +3|
|--- |--- |--- |--- |--- |--- |--- |
Normal Distribution |  97.728 |  99.866 | 91.141 |  97.852 | 99.654 |  99.997 |
standard Exponential |  95.017 |  98.173 | 80.897 |  88.188 | 94.434 |  98.150 |
Exponential $\(lambda\)$ = 0.5 |  95.023 |  98.173 | 80.910 |  88.209 | 94.452 |  98.156 |
Exponential $$\lambda$$ = 2.0 |  95.020 |  98.168 | 80.895 |  88.190 | 94.440 |  98.146 |
Exponential $\lambda$ = 0.1 |  95.026 |  98.170 | 80.894 |  88.185 | 94.459 |  98.153 |
Gamma shape $\alpha$ =.1 |  96.223 |  97.770 | 55.797 |  57.427 | 80.198 |  83.239 |
Gamma shape $\alpha$ =.5 |  94.964 |  97.797 | 74.449 |  80.918 | 91.118 |  95.756 |
Gamma shape $\alpha$ =1 |  95.026 |  98.164 | 80.920 |  88.201 | 94.445 |  98.141 |
Gamma shape $\alpha$ =3 |  95.578 |  98.825 | 85.686 |  93.114 | 97.171 |  99.495 |
Gamma shape $\alpha$ =5 |  95.902 |  99.074 | 86.934 |  94.318 | 97.871 |  99.719 |
Gamma shape $\alpha$ =10 |  96.319 |  99.326 | 88.186 |  95.442 | 98.497 |  99.870 |
Power shape $k$= .01 |  98.113 |  98.491 | 50.552 |  50.697 | 75.522 |  75.832 |
Power shape $k$=.1 |  93.070 |  96.299 | 55.797 |  57.428 | 80.439 |  83.758 |
Power shape $k$=.5 |  96.428 |  100.000 | 82.632 |  94.838 | 100.000 |  100.000 |
Power shape $k$=1 |  100.000 |  100.000 | 99.966 |  100.000 | 100.000 |  100.000 |
Power shape $k$=5 |  100.000 |  100.000 | 100.000 |  100.000 | 100.000 |  100.000 |
Power shape $k$=10 |  100.000 |  100.000 | 100.000 |  100.000 | 100.000 |  100.000 |
Power shape $k$=100 |  100.000 |  100.000 | 100.000 |  100.000 | 100.000 |  100.000 |
Beta $\alpha$ = $\beta$ = 0.5 |  100.000 |  100.000 | 100.000 |  100.000 | 100.000 |  100.000 |
Beta $\alpha$ = 1 $\beta$ = 1 |  100.000 |  100.000 | 100.000 |  100.000 | 100.000 |  100.000 |
Beta $\alpha$ = 1 $\beta$ = 3 |  95.230 |  99.516 | 84.996 |  93.589 | 98.677 |  100.000 |
Beta $\alpha$ = $\beta$ = 2 |  99.198 |  100.000 | 93.722 |  100.000 | 100.000 |  100.000 |
Beta $\alpha$ = 2 $\beta$ = 5 |  96.138 |  99.653 | 87.995 |  95.958 | 99.221 |  100.000 |
Beta $\alpha$ = 5 $\beta$ = 1 |  100.000 |  100.000 | 100.000 |  100.000 | 100.000 |  100.000 |
biNormal $\mu$ = 3 & 6 $\sigma^2$ = 1 & 1.5 |  97.393 |  99.917 | 88.794 |  97.943 | 99.900 |  100.000 |

## Points of interests
* for the Exponential distribution, the results are relatively close from the Normal distribution when it is taken into account that the exponential one is not symmetrical. The results do not vary notably when the values for $lambda$ vary.
* for the Gamma distribution the results do vary depending on the $$alpha$$ parameter used.
* for the Power law distribution the results vary significantly and for some shapes there is no outliers. 
* for the Beta distribution, as for the Power Law, the results vary depending on the alpha and beta values and in some cases there is no outliers.

## Conclusion
The results indicate that there are some differences depending on the underlying distribution. In some cases the differences are not so important in other cases they are (no outliers). In the situation that a specific number of outlier observations (say 100) should be reviewed, the outliers techniques as well as the underlying distribution should be analysed in order to benefit from these techniques. 

## Implementation details
Here is the code used to generate the above table; generated with Numpy version 1.18.1 and Python version 3.8.1.

```python
import numpy as np
from scipy import stats


def print_outliers_rank_from_distribtion(data):
    c_mean = np.mean(data[0])
    c_SD = np.std(data[0])
    c_mean_2SD = c_mean + 2.0 * c_SD
    c_mean_3SD = c_mean + 3.0 * c_SD
    c_MAD = stats.median_absolute_deviation(data[0], scale=1)
    c_median = np.median(data[0])
    c_25pctl = np.percentile(data[0], 25, interpolation='linear')
    c_75pctl = np.percentile(data[0], 75, interpolation='linear')
    c_IQD = np.abs(c_75pctl - c_25pctl)
    rank_mean_2SD = stats.percentileofscore(data[0], c_mean_2SD)
    rank_mean_3SD = stats.percentileofscore(data[0], c_mean_3SD)
    rank_median_2MAD = stats.percentileofscore(data[0], c_median + 2.0 * c_MAD)
    rank_median_2MAD = stats.percentileofscore(data[0], c_median + 3.0 * c_MAD)
    rank_median_2IQD = stats.percentileofscore(data[0], c_median + 2.0 * c_IQD)
    rank_median_3IQD = stats.percentileofscore(data[0], c_median + 3.0 * c_IQD)

    print(data[1], "| ", '{:3.3f}'.format(rank_mean_2SD),
          "| ", '{:3.3f}'.format(
        rank_mean_3SD), "|", '{:3.3f}'.format(rank_median_2MAD),
        "| ", '{:3.3f}'.format(
        rank_median_2MAD), "|", '{:3.3f}'.format(rank_median_2IQD),
        "| ", '{:3.3f}'.format(rank_median_3IQD), "|")
```



